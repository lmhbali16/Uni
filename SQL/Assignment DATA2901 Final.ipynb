{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Assignment: Neighbourhood Cyclability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import csv\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import shapefile\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.wkt import loads\n",
    "import descartes\n",
    "from shapely.geometry import Point, Polygon\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for server connection. Used from DATA2901 week 9 lab jupyter notebook\n",
    "\n",
    "def pgconnect(unikey,pw):\n",
    "    YOUR_UNIKEY = unikey\n",
    "    YOUR_PW     = pw\n",
    "    try: \n",
    "        conn = psycopg2.connect(host='soit-db-pro-1.ucc.usyd.edu.au',\n",
    "                                database='y19s1d2x01_'+YOUR_UNIKEY,\n",
    "                                user='y19s1d2x01_'+YOUR_UNIKEY, \n",
    "                                password=YOUR_PW)\n",
    "        \n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used from DATA2901 week 9 lab jupyter notebook. Excecute commits and queries. \n",
    "#Connect to the server and to Public Schema.\n",
    "\n",
    "#\n",
    "\n",
    "conn = pgconnect(\"mile3901\", \"480133780\")\n",
    "\n",
    "\n",
    "\n",
    "#function to commit our SWL statements\n",
    "def pgexec( conn, sqlcmd, args, msg, silent=False ):\n",
    "   retval = False\n",
    "   with conn:\n",
    "      with conn.cursor() as cur:\n",
    "         try:\n",
    "            if args is None:\n",
    "               cur.execute(sqlcmd)\n",
    "            else:\n",
    "               cur.execute(sqlcmd, args)\n",
    "            if silent == False: \n",
    "                print(\"success: \" + msg)\n",
    "            retval = True\n",
    "         except Exception as e:\n",
    "            if silent == False: \n",
    "                print(\"db error: \")\n",
    "                print(e)\n",
    "   return retval\n",
    "\n",
    "def pgquery( conn, sqlcmd, args=None, msg=False, returntype='tuple'):\n",
    "    \"\"\" utility function to execute some SQL query statement\n",
    "        it can take optional arguments (as a dictionary) to fill in for placeholders in the SQL\n",
    "        will return the complete query result as return value - or in case of error: None\n",
    "        error and transaction handling built-in (by using the 'with' clauses)\"\"\"\n",
    "    retval = None\n",
    "    with conn:\n",
    "        cursortype = None if returntype != 'dict' else psycopg2.extras.RealDictCursor\n",
    "        with conn.cursor(cursor_factory=cursortype) as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if (cur.description != None ):\n",
    "                    retval = cur.fetchall() # we use fetchall() as we expect only _small_ query results\n",
    "                if msg != False:\n",
    "                    print(\"success: \" + msg)\n",
    "            except psycopg2.DatabaseError as e:\n",
    "                if e.pgcode != None and msg:\n",
    "                    print(\"db read error: \"+msg)\n",
    "                    print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return retval\n",
    "pgexec(conn, \"set search_path to public\", None, \"set the working space to public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Integration and Database Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and Cleaning Datasets\n",
    "\n",
    "pd = open(\"Neighbourhoods.csv\",'r')\n",
    "file = open(\"Clean_Neighbourhoods.csv\", 'w')\n",
    "flag = False#first row\n",
    "\n",
    "for i in pd:\n",
    "    i = i.split(\",\")\n",
    "\n",
    "\n",
    "    if len(i) == 6 and flag:#if no missing value and not first row\n",
    "\n",
    "        if i[5] == \"\\n\":\n",
    "            i[5] = \"0\\n\"#last value is empty then just replace it with 0\n",
    "        elif i[5][0] == \"-\": #if the value is less than 0 then it's a incorrect value\n",
    "            i[5] = \"-1\\n\"\n",
    "\n",
    "        for j in range(2,len(i)-1):\n",
    "            if i[j] == \"\":#if no value\n",
    "                i[j] = \"0\"\n",
    "            elif i[j][0] == \"-\":#if incorrect value\n",
    "                i[j] = \"-1\"\n",
    "\n",
    "        if i[1] == \"\":\n",
    "            i[1] = \"NULL\"\n",
    "\n",
    "    file.write(\"{},{},{},{},{},{}\".format(i[0],i[1],i[2],i[3],i[4],i[5]))\n",
    "    flag = True#This was the first row\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and Cleaning Datasets\n",
    "\n",
    "pd = open(\"BusinessStats.csv\",'r')\n",
    "file = open(\"Clean_BusinessStats.csv\", 'w+')\n",
    "flag = False#first row\n",
    "\n",
    "for i in pd:\n",
    "    i = i.split(\",\")\n",
    "\n",
    "\n",
    "    if len(i) == 7 and flag:#if no missing value and not first row\n",
    "\n",
    "        if i[6] == \"\\n\":\n",
    "            i[6] = \"0\\n\"\n",
    "        elif i[6][0] == \"-\":\n",
    "            i[6] = \"-1\\n\"\n",
    "\n",
    "        for j in range(1,len(i)-1):\n",
    "            if i[j] == \"\":#if no value\n",
    "                i[j] = \"0\"\n",
    "            elif i[j][0] == \"-\":#if incorrect value\n",
    "                i[j] = \"-1\"\n",
    "\n",
    "\n",
    "\n",
    "    file.write(\"{},{},{},{},{},{},{}\".format(i[0],i[1],i[2],i[3],i[4],i[5],i[6]))\n",
    "    flag = True#This was the first row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and Cleaning Datasets\n",
    "\n",
    "pd = open(\"CensusStats.csv\",'r')\n",
    "file = open(\"Clean_CensusStats.csv\", 'w+')\n",
    "flag = False\n",
    "\n",
    "for i in pd:\n",
    "\n",
    "    i = i.split(',')\n",
    "\n",
    "    if len(i) == 3 and flag:\n",
    "\n",
    "        if i[1] == '':\n",
    "            i[1] = '0'\n",
    "        elif i[1][0] == '-':\n",
    "            i[i] ='0';\n",
    "\n",
    "\n",
    "        if i[2] == \"\\n\":\n",
    "            i[2] = \"0\\n\"\n",
    "        elif i[2][0] == \"-\":\n",
    "            i[2] = \"-1\\n\"\n",
    "\n",
    "\n",
    "    flag = True\n",
    "    file.write(\"{},{},{}\".format(i[0],i[1],i[2]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing data in dictionaries\n",
    "\n",
    "data_BikeSharingPods = list(csv.DictReader(open(\"BikeSharingPods.csv\")))\n",
    "data_BusinessStats = list(csv.DictReader(open(\"Clean_BusinessStats.csv\")))\n",
    "data_Neighbourhood = list(csv.DictReader(open(\"Clean_Neighbourhoods.csv\")))\n",
    "data_CensusStats = list(csv.DictReader(open(\"Clean_CensusStats.csv\")))\n",
    "data_StatisticalAreas = list(csv.DictReader(open(\"StatisticalAreas.csv\")))\n",
    "print(data_CensusStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables if they exist. Create tables\n",
    "\n",
    "\n",
    "\n",
    "pgexec(conn, \"\"\"\n",
    "drop table if exists StatisticalAreas;\n",
    "drop table if exists Neighbourhoods;\n",
    "drop table if exists CensusStats;\n",
    "drop table if exists BusinessStats;\n",
    "drop table if exists BikeSharingPods;\n",
    "\"\"\", None, \"Drop tables if they exists\")\n",
    "\n",
    "pgexec(conn, \"\"\"create table StatisticalAreas(\n",
    "area_id int primary key,\n",
    "name varchar(50),\n",
    "parent_id int\n",
    ");\n",
    "create table Neighbourhoods(\n",
    "area_id int,\n",
    "name varchar(50) not NULL,\n",
    "land_area float,\n",
    "population int,\n",
    "dwellings int,\n",
    "business int,\n",
    "foreign key (area_id) references StatisticalAreas(area_id)\n",
    ");\n",
    "\n",
    "create table CensusStats(\n",
    "area_id int,\n",
    "income int,\n",
    "rent int,\n",
    "foreign key (area_id) references StatisticalAreas(area_id)\n",
    ");\n",
    "\n",
    "create table BusinessStats(\n",
    "area_id int,\n",
    "num_business int,\n",
    "retail_trade int,\n",
    "acc_food int, \n",
    "health_social int,\n",
    "ed_training int,\n",
    "art int,\n",
    "foreign key (area_id) references StatisticalAreas(area_id)\n",
    ");\n",
    "\n",
    "create table BikeSharingPods(\n",
    "station_id int primary key,\n",
    "name varchar(1000),\n",
    "bike int,\n",
    "scooter int,\n",
    "latitude float,\n",
    "longitude float,\n",
    "description varchar(1000)\n",
    "\n",
    ");\"\"\", None, \"Create tables\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data into the table\n",
    "\n",
    "pgexec(conn, \"\"\"Truncate table Neighbourhoods;\n",
    "Truncate table Censusstats;\n",
    "truncate table businessStats;\n",
    "truncate table BikeSharingpods;\"\"\",None, \"Truncate Tables\")\n",
    "\n",
    "for row in data_StatisticalAreas:\n",
    "    pgexec(conn,\"\"\"insert into statisticalareas(area_id,name,parent_id) values(%(area_id)s,%(area_name)s,%(parent_area_id)s)\"\"\",row,\"Row copied\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_BusinessStats:\n",
    "    pgexec(conn,\"\"\"insert into BusinessStats(area_id,num_business, retail_trade, acc_food,health_social,ed_training,art) values(%(area_id)s,%(num_businesses)s,%(retail_trade)s,%(accommodation_and_food_services)s,%(health_care_and_social_assistance)s,%(education_and_training)s,%(arts_and_recreation_services)s)\"\"\",row,\"Row copied\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_BikeSharingPods:\n",
    "    pgexec(conn, \"Insert into BikeSharingPods(station_id,name,bike,scooter,latitude,longitude, description) values(%(station_id)s, %(name)s, %(num_bikes)s,%(num_scooters)s,%(latitude)s,%(longitude)s,%(description)s)\",row,\"Row copied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_Neighbourhood:\n",
    "    pgexec(conn,\"\"\"insert into neighbourhoods(area_id, name,land_area,population,dwellings,business) values(%(area_id)s,%(area_name)s,%(land_area)s,%(population)s,%(number_of_dwellings)s,%(number_of_businesses)s)\"\"\",row,\"Row copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_CensusStats:\n",
    "\n",
    "    pgexec(conn,\"\"\"insert into censusstats(area_id,income,rent) values(%(area_id)s,%(median_annual_household_income)s,%(avg_monthly_rent)s)\"\"\",row,\"Row copied\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Geom Data into a new table called Area\n",
    "\n",
    "sf = shapefile.Reader(\"file/SA2_2016_AUST.shp\", encoding=\"iso-8859-1\")\n",
    "\n",
    "\n",
    "if (sf.shapeType == shapefile.POLYGON):\n",
    "    shapes = sf.shapes()\n",
    "    print(\"#shapes: \",len(shapes))\n",
    "    for shape in shapes:\n",
    "       print(shape.__geo_interface__['type'], len(shape.points), \"points; bounding box:\", shape.bbox)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_schema = '''CREATE TABLE Area (\n",
    "                     area_id NUMERIC, \n",
    "                     fivedig_id NUMERIC,\n",
    "                     name VARCHAR(100),\n",
    "                     geom GEOMETRY(Polygon,4283))''' \n",
    "\n",
    "pgquery(conn, \"DROP TABLE Area\", msg=\"cleared old table\")\n",
    "pgquery(conn, area_schema, msg=\"created Area table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT area_id FROM Neighbourhoods''' \n",
    "\n",
    "list1=pgquery(conn, query, msg=\"Neighbourhoods\")\n",
    "\n",
    "neighbourhood_list =[]\n",
    "for i in list1:\n",
    "    neighbourhood_list.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO Area VALUES ( %(area_id)s, %(fivedig_id)s, %(name)s,\n",
    "                                            ST_GEOMFROMTEXT(%(geom)s, 4283) )\"\"\"\n",
    "\n",
    "shapes = sf.shapes()\n",
    "records= sf.records()\n",
    "\n",
    "row = {}\n",
    "for i in range(0, len(shapes)):\n",
    "    record = sf.record(i)\n",
    "    shape  = sf.shape(i)\n",
    "    if int(record[0]) in neighbourhood_list:\n",
    "        row['area_id']=record[0]\n",
    "        row['fivedig_id']=record[1]\n",
    "        row['name']=record[2]\n",
    "        #print(row)\n",
    "\n",
    "        # prepare the polygon data\n",
    "        # this is a bit complex with our dataset as it has complex polygons, some with multiple parts...\n",
    "        row['geom']=\"POLYGON((\"\n",
    "        i=0\n",
    "        for x, y in shape.points:\n",
    "           row['geom']+=\"%s %s,\" % (x,y)\n",
    "           # check for start of a new polygon part\n",
    "           i += 1\n",
    "           if i in shape.parts:\n",
    "               row['geom']= re.sub(\",$\", \"),(\", row['geom'])\n",
    "        # properly end the polygon string\n",
    "        row['geom'] = re.sub(\",$\", \"))\", row['geom'])\n",
    "\n",
    "        # finally: insert new row into the table\n",
    "        pgquery(conn, insert_stmt, args=row, msg=\"inserted \"+str(record[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''alter table neighbourhoods\n",
    "        add geom GEOMETRY(Polygon,4283)\n",
    "'''\n",
    "\n",
    "pgquery(conn,query,msg=\"alter table Neighbourhoods, adding geom column\")\n",
    "\n",
    "query='''    \n",
    "update neighbourhoods\n",
    "set geom = area.geom\n",
    "from area where neighbourhoods.area_id=area.area_id\n",
    "'''\n",
    "\n",
    "pgquery(conn,query,msg=\"update geom column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alter table Bikesharingpods\n",
    "\n",
    "query = '''ALTER TABLE BikeSharingPods\n",
    "               ADD geom_pts GEOMETRY(Point,4283);\n",
    "               \n",
    "            '''\n",
    "pgquery(conn, query, msg=\"row added\")\n",
    "\n",
    "query = '''UPDATE BikeSharingPods\n",
    "           SET geom_pts = ST_SetSRID(ST_MakePoint(longitude,latitude),4283)\n",
    "'''\n",
    "pgquery(conn, query, msg=\"row updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Index\n",
    "\n",
    "query='''drop index if exists Area_id_index;\n",
    "create unique index Area_id_index on Neighbourhoods(area_id);\n",
    "drop index if exists Bike_geom_index;\n",
    "create index Bike_geom_index on Bikesharingpods using  GIST (geom_pts);\n",
    "\n",
    "'''\n",
    "\n",
    "pgquery(conn, query, msg=\"create index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table of spatial join\n",
    "\n",
    "query = '''\n",
    "            create table spatial_join as\n",
    "            select area_id,count(station_id) as \"num_station\", count(station_id)/land_area as \"ratio\" from Neighbourhoods n\n",
    "            left outer join Bikesharingpods b ON ST_DWITHIN(N.geom,b.geom_pts,0.02)\n",
    "            group by area_id, land_area\n",
    "'''\n",
    "pgquery(conn, query, msg=\"spatial join complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Cyclability Analysis (Note: Indexes are already created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop views if they exists\n",
    "\n",
    "query ='''\n",
    "drop view if exists score_final;\n",
    "drop view if exists score_bike;\n",
    "drop view if exists score_pop;\n",
    "drop view if exists score_dwelling;\n",
    "drop view if exists score_service;\n",
    "\n",
    "\n",
    "'''\n",
    "pgquery(conn, query, msg=\"dropped views\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create views of z-score for each category\n",
    "\n",
    "#population density\n",
    "query = '''create view score_pop\n",
    "as select area_id, name,((n.population/n.land_area) - n1.average)/n1.std as \"z_score\" from\n",
    "(select avg(population/land_area) as \"average\", stddev(population/land_area) as \"std\" from neighbourhoods)\n",
    "as n1,\n",
    "Neighbourhoods n;\n",
    "'''\n",
    "pgquery(conn, query, msg=\"score_pop view\")\n",
    "\n",
    "#Dwelling densinty\n",
    "\n",
    "query = '''create view score_dwelling\n",
    "as select n.area_id, name, ((n.dwellings/n.land_area)-n1.average)/ n1.std as \"z_score\" from\n",
    "(select avg(dwellings/land_area) as \"average\", stddev(dwellings/land_area) as \"std\" from neighbourhoods) as n1,\n",
    "neighbourhoods n;\n",
    "'''\n",
    "pgquery(conn, query, msg=\"score_dwelling\")\n",
    "\n",
    "#Business service score\n",
    "\n",
    "query='''\n",
    "    create view score_service\n",
    "as select\n",
    "n.area_id, n.name, ((b.retail_trade/nullif(cast(b.num_business as float),0))-b1.avg_retail)/b1.std_retail as \"retail_score\",\n",
    "((b.acc_food/nullif(cast(b.num_business as float),0))-b1.avg_food)/b1.std_food as \"food_score\",\n",
    "((b.health_social/nullif(cast(b.num_business as float),0))-b1.avg_health)/b1.std_health as \"health_score\",\n",
    "((b.ed_training/nullif(cast(b.num_business as float),0))-b1.avg_ed)/b1.std_ed as \"ed_score\",\n",
    "((b.art/nullif(cast(b.num_business as float),0))-b1.avg_art)/b1.std_art as \"art_score\" from\n",
    "(select avg(cast(b.retail_trade as float)/nullif(cast(b.num_business as float),0)) as \"avg_retail\", \n",
    "\tavg(cast(b.acc_food as float)/nullif(cast(b.num_business as float),0)) as \"avg_food\",\n",
    "\tavg(cast(b.health_social as float)/nullif(cast(b.num_business as float),0)) as \"avg_health\",\n",
    "\tavg(cast(b.ed_training as float)/nullif(cast(b.num_business as float),0)) as \"avg_ed\", \n",
    "\tavg(cast(b.art as float)/nullif(cast(b.num_business as float),0)) as \"avg_art\",\n",
    "\tstddev(cast(b.retail_trade as float)/nullif(cast(b.num_business as float),0)) as \"std_retail\",\n",
    "\tstddev(cast(b.acc_food as float)/nullif(cast(b.num_business as float),0)) as \"std_food\", \n",
    "\tstddev(cast(b.health_social as float)/nullif(cast(b.num_business as float),0)) as \"std_health\",\n",
    "\tstddev(cast(b.ed_training as float)/nullif(cast(b.num_business as float),0)) as \"std_ed\", \n",
    "\tstddev(cast(b.art as float)/nullif(cast(b.num_business as float),0)) as \"std_art\" from businessstats b) as b1, Neighbourhoods n\n",
    "left outer join businessstats b on n.area_id=b.area_id\n",
    "'''\n",
    "\n",
    "pgquery(conn, query, msg=\"score_service\")\n",
    "\n",
    "#Bikepod z-score\n",
    "\n",
    "query='''\n",
    "create view score_bike as\n",
    "select n.area_id, (b.ratio-b1.average)/b1.std as \"score\" from \n",
    "(select stddev(ratio) as \"std\", avg(ratio) as \"average\" from spatial_join) as b1, neighbourhoods n\n",
    "left outer join spatial_join b on b.area_id = n.area_id;\n",
    "'''\n",
    "\n",
    "pgquery(conn, query, msg=\"score_bike\")\n",
    "\n",
    "\n",
    "#Adding all the score together\n",
    "query= '''\n",
    "create view final_score as\n",
    "select n.area_id,n.name,coalesce(s1.score ,0)+s2.z_score+s3.z_score+coalesce(s4.retail_score,0)+coalesce(s4.food_score,0)+coalesce(s4.health_score,0)+coalesce(s4.ed_score,0)+coalesce(s4.art_score,0) as \"final z score\"\n",
    "from neighbourhoods n\n",
    "left outer join score_bike s1 using (area_id)\n",
    "left outer join score_dwelling s2 using (area_id)\n",
    "left outer join score_pop s3 using(area_id)\n",
    "left outer join score_service s4 using (area_id)\n",
    "\n",
    "\n",
    "'''\n",
    "pgquery(conn, query, msg=\"final_score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: DATA2901 Task for Advanced Class Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''Select * from final_score;'''\n",
    "\n",
    "df=pd.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.to_csv(\"z_score_correct.csv\")\n",
    "\n",
    "\n",
    "data_Neighbourhood = pd.read_csv(open(\"z_score_correct.csv\"))\n",
    "\n",
    "data_Neighbourhood.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs = []\n",
    "for i in range(len(data_Neighbourhood['name'])):\n",
    "    t = data_Neighbourhood['name'][i].split(' - ')\n",
    "    for sub in t:\n",
    "        suburbs.append([data_Neighbourhood['area_id'][i],sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mentions(forum_text, suburbs):\n",
    "    rem_list = ['North', 'South', 'East', 'West']\n",
    "    mentions = []\n",
    "    for entry in forum_text:\n",
    "        [mentions.append(suburb) for suburb in suburbs if suburb[1] in entry.text and suburb[1] not in rem_list] \n",
    "    # above line takes away N,E,S,W loses some reference as these could be useful.\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://www.bicycles.net.au/forums/viewtopic.php?t=89780\"\n",
    "webpage_source = requests.get(base_url).text\n",
    "page_content = BeautifulSoup(webpage_source, 'html5lib')\n",
    "num_pages = int(page_content.find(class_=\"pagination\").find('ul').find_all('li')[-2].text)\n",
    "overall_mentions = []\n",
    "# define suburbs again\n",
    "\n",
    "for i in range(num_pages):\n",
    "    if i == 0:\n",
    "        first_page = False\n",
    "        whole_text = page_content.find_all(class_ = 'content')\n",
    "        first_page_forum_text = whole_text[1:]\n",
    "        mentions = get_mentions(first_page_forum_text, suburbs)\n",
    "        [overall_mentions.append(i) for i in mentions]\n",
    "    else:\n",
    "        try:\n",
    "            webpage_source = requests.get(base_url + '&start=' + str(i*25)).text\n",
    "            page_content = BeautifulSoup(webpage_source, 'html5lib')\n",
    "            forum_text = page_content.find_all(class_ = 'content')\n",
    "            mentions = get_mentions(forum_text, suburbs)\n",
    "            [overall_mentions.append(i) for i in mentions] \n",
    "        except BaseException:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(overall_mentions)\n",
    "area_codes, names = zip(*overall_mentions)\n",
    "values, counts = np.unique(area_codes, return_counts=True)\n",
    "sub_count =  [[values[i], counts[i]] for i in range(len(values))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sub_count.remove([117031337, 28])\n",
    "    sub_count.remove([125041492, 13])\n",
    "except ValueError:\n",
    "    pass\n",
    "final_sub_count = sub_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Neighbourhood['op_count'] = np.zeros(len(data_Neighbourhood))\n",
    "\n",
    "for j in final_sub_count:\n",
    "        data_Neighbourhood['op_count'][data_Neighbourhood['area_id'] == j[0]] = j[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_Neighbourhood[data_Neighbourhood['op_count'] > 0]\n",
    "train_x = train_data['final z score']\n",
    "train_y = train_data['op_count']\n",
    "\n",
    "plt.scatter(train_x,train_y )\n",
    "plt.title('Mention Count vs Z Score (Training Data)')\n",
    "plt.xlabel('Z Score')\n",
    "plt.ylabel('Mention Count')\n",
    "plt.savefig('initial_mcvzs_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use the 4/5 predictor variables used in the z-score\n",
    "model = smf.ols(formula='train_y ~ train_x', data=train_data) \n",
    "reg = model.fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-15,25, 1000)\n",
    "y_hat = 1.9104 + 0.0415 * x\n",
    "plt.plot(x, y_hat)\n",
    "plt.scatter(data_Neighbourhood['final z score'], data_Neighbourhood['op_count'])\n",
    "plt.title('Mention Count vs Z Score (Reg Line and Unclassified Data)')\n",
    "plt.xlabel('Z Score')\n",
    "plt.ylabel('Mention Count')\n",
    "plt.savefig('with_reg_mcvzs_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_Neighbourhood[data_Neighbourhood['op_count'] == 0]\n",
    "test_data['op_count'] = (1.9104 + 0.0415 * test_data['final z score']).round(0)\n",
    "data_Neighbourhood['op_count'][data_Neighbourhood['op_count'] == 0] = test_data['op_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-15,27, 1000)\n",
    "y_hat = 1.9104 + 0.0415 * x\n",
    "plt.plot(x, y_hat)\n",
    "plt.scatter(data_Neighbourhood['final z score'], data_Neighbourhood['op_count'])\n",
    "plt.title('Mention Count vs Z Score (Classified Data)')\n",
    "plt.xlabel('Z Score')\n",
    "plt.ylabel('Mention Count')\n",
    "plt.savefig('classified_mcvzs_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave = np.mean(data_Neighbourhood['op_count'])\n",
    "std = np.std(data_Neighbourhood['op_count'])\n",
    "\n",
    "data_Neighbourhood['extra_z_score'] = (data_Neighbourhood['op_count'] - ave)/std\n",
    "data_Neighbourhood['final_z_score'] = data_Neighbourhood['final z score'] + data_Neighbourhood['extra_z_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Neighbourhood.to_csv('z_score_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload own dataset and final z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore = pd.read_csv(\"z_score_final.csv\",index_col=False)\n",
    "category = np.arange(-4,5,1)*np.std(zscore['final_z_score'])\n",
    "point = np.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.zeros(len(zscore['final_z_score']))\n",
    "\n",
    "for i in range(len(value)):\n",
    "    \n",
    "    for j in range(len(category)):\n",
    "        if zscore['final_z_score'][i] < category[j]:\n",
    "            value[i] = point[j]\n",
    "            break\n",
    "        elif zscore['final_z_score'][i] > category[-1]:\n",
    "            \n",
    "            value[i] = point[-1]\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore['op_count'] = pd.to_numeric(zscore['op_count'],downcast='integer')\n",
    "zscore['point']=value\n",
    "zscore['point'] = pd.to_numeric(zscore['point'],downcast='integer')\n",
    "zscore.to_csv(\"z_score_new.csv\")\n",
    "\n",
    "dict = list(csv.DictReader(open(\"z_score_new.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "    Create table Z_Score(\n",
    "        area_id int,\n",
    "        name varchar(100),\n",
    "        z_score float,\n",
    "        op_count int,\n",
    "        op_z_score float,\n",
    "        final_z_score float,\n",
    "        point int,\n",
    "        foreign key (area_id) references StatisticalAreas(area_id)\n",
    "    \n",
    "    \n",
    "    )\n",
    "\n",
    "'''\n",
    "\n",
    "pgquery(conn, query, msg=\"Z_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dict:\n",
    "    query =\"Insert into Z_score(area_id,name,z_score,op_count,op_z_score,final_z_score,point) values(%(area_id)s,%(name)s,%(final z score)s,%(op_count)s,%(extra_z_score)s,%(final_z_score)s,%(point)s)\"\n",
    "    pgexec(conn,query,i,\"Row copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation analysis\n",
    "    \n",
    "\n",
    "#Create table for it\n",
    "query='''\n",
    "create table Corr(\n",
    "area_id int,\n",
    "name varchar(50),\n",
    "z_score float,\n",
    "income int,\n",
    "rent int\n",
    ");\n",
    "\n",
    "INSERT INTO Corr(area_id)\n",
    "SELECT area_id FROM Z_Score;\n",
    "'''\n",
    "pgquery(conn, query, msg=\"Corr\")\n",
    "\n",
    "\n",
    "\n",
    "query='''\n",
    "UPDATE Corr\n",
    "SET name = (SELECT z.name \n",
    "                     FROM Z_Score z WHERE z.area_id = Corr.area_id )\n",
    "'''\n",
    "pgquery(conn, query, msg=\"corr_table_update1\")\n",
    "\n",
    "\n",
    "query='''\n",
    "UPDATE Corr\n",
    "SET z_score = (SELECT z.final_z_score\n",
    "                     FROM Z_Score z WHERE z.area_id = Corr.area_id )\n",
    "'''\n",
    "pgquery(conn, query, msg=\"corr_table_update2\")\n",
    "\n",
    "\n",
    "query='''\n",
    "UPDATE Corr\n",
    "SET income = (SELECT c.income\n",
    "                     FROM CensusStats c WHERE c.area_id = Corr.area_id )\n",
    "'''\n",
    "pgquery(conn, query, msg=\"corr_table_update3\")\n",
    "\n",
    "\n",
    "query='''\n",
    "UPDATE Corr\n",
    "SET rent = (SELECT c.rent\n",
    "                     FROM CensusStats c WHERE c.area_id = Corr.area_id )\n",
    "'''\n",
    "pgquery(conn, query, msg=\"corr_table_update4\")\n",
    "\n",
    "\n",
    "query='''\n",
    "SELECT corr(z_score, income)\n",
    "FROM Corr\n",
    "'''\n",
    "corr_income = pgquery(conn, query, msg=\"corr() study of score and income\")\n",
    "print(corr_income)\n",
    "\n",
    "\n",
    "query='''\n",
    "SELECT corr(z_score, rent)\n",
    "FROM Corr\n",
    "'''\n",
    "corr_rent = pgquery(conn, query, msg=\"corr() study of score and rent\")\n",
    "print(corr_rent)\n",
    "\n",
    "query='''\n",
    "SELECT * FROM Corr'''\n",
    "df = pd.read_sql_query(query,conn)\n",
    "df.to_csv(\"corr.csv\",sep=',')\n",
    "corr_data = list(csv.DictReader(open(\"corr.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defin lists for ploting\n",
    "score = []\n",
    "rent = []\n",
    "income = []\n",
    "\n",
    "#Fill the lists\n",
    "for i in corr_data:\n",
    "    score.append(float(i['z_score']))\n",
    "    rent.append(int(i['rent']))\n",
    "    income.append(int(i['income']))\n",
    "\n",
    "#Plot a scatter graph by rent and score\n",
    "plt.scatter(score, rent, color='r',marker='X',s=0.5)\n",
    "plt.title('Median Rent vs. Z score')\n",
    "plt.xlabel('Z Score')\n",
    "plt.ylabel('Median Rent')\n",
    "plt.savefig(\"Rent_z_score.png\", dpi =100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = score, y = rent)\n",
    "plt.title('Median Rent vs. score')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Median Rent')\n",
    "plt.savefig(\"Rent_z_score.png\", dpi =100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a scatter graph by income and score\n",
    "plt.scatter(score, income, color='r',marker='X',s=0.5)\n",
    "plt.title('Median Income vs. Z Score')\n",
    "plt.xlabel('Z Score')\n",
    "plt.ylabel('Median Income')\n",
    "plt.savefig(\"Income_z_score.png\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = score, y = income)\n",
    "plt.title(\"Median Income vs Score\")\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Median Income')\n",
    "plt.savefig(\"Income_z_score.png\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "alter table Neighbourhoods\n",
    "add op_count int;\n",
    "\n",
    "update neighbourhoods\n",
    "set op_count = z.op_count\n",
    "from z_score z where Neighbourhoods.area_id=z.area_id;\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "pgquery(conn,query,msg=\"adding colums\")\n",
    "\n",
    "query='''alter table Neighbourhoods\n",
    "            add point int;\n",
    "         update neighbourhoods\n",
    "             set point= z.point\n",
    "             from z_score z where z.area_id=neighbourhoods.area_id;'''\n",
    "\n",
    "pgquery(conn,query,msg=\"adding colums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''select area_id,name,point,Polygon(geom) from Neighbourhoods'''\n",
    "\n",
    "\n",
    "neighbour = pd.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"SELECT POLYGON(geom) FROM Neighbourhoods\"\"\"\n",
    "arealist = pgquery(conn, query, msg=\".\")\n",
    "\n",
    "new_arealist=[]\n",
    "for j in arealist:\n",
    "    for i in range(len(j)):\n",
    "        new_arealist.append(Polygon(ast.literal_eval(j[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour['polygon'] = new_arealist\n",
    "crs = {'init': 'epsg:4283'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= '''select station_id,name ,geom_pts from Bikesharingpods;\n",
    "\n",
    "'''\n",
    "\n",
    "bikepod =pd.read_sql_query(query,conn)\n",
    "\n",
    "query=\"\"\"SELECT Point(geom_pts) FROM Bikesharingpods\"\"\"\n",
    "pods = pgquery(conn, query, msg=\".\")\n",
    "\n",
    "new_pods=[]\n",
    "for j in pods:\n",
    "    for i in range(len(j)):\n",
    "        new_pods.append(Point(ast.literal_eval(j[i])))\n",
    "        \n",
    "bikepod['geom_pts'] =new_pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_gp = gpd.GeoDataFrame(bikepod,crs=crs,geometry=bikepod['geom_pts'])\n",
    "gp = gpd.GeoDataFrame(neighbour,crs=crs,geometry=neighbour['polygon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 10))\n",
    "\n",
    "gp.plot(ax=ax,column='point',figsize=(20,20),legend=True)\n",
    "plt.xlim(150.95,151.35)\n",
    "plt.ylim(-34.0,-33.7)\n",
    "plt.title(\"Cyclability Score of Sydney Suburbs\")\n",
    "plt.savefig(\"Cyclability.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 10))\n",
    "\n",
    "gp.plot(ax=ax,column='point',figsize=(20,20),legend=True)\n",
    "bike_gp.plot(ax=ax,c='r')\n",
    "plt.xlim(150.95,151.35)\n",
    "plt.ylim(-34.0,-33.7)\n",
    "plt.title(\"Cyclability Score of Sydney Suburbs\")\n",
    "plt.savefig(\"Cyclability.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select name, final_z_score from Z_score\n",
    "order by final_z_score desc\n",
    "limit 5;\n",
    "\n",
    "'''\n",
    "pgquery(conn, query, msg=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select name, final_z_score from Z_score\n",
    "order by final_z_score asc\n",
    "limit 5;\n",
    "\n",
    "'''\n",
    "pgquery(conn, query, msg=\".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
